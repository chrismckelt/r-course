p_load("shinyjs")
p_load("choroplethr")
p_load("choroplethrMaps")
p_load("DescTools")
p_load("readxl")
p_load("devtools")
p_load("ggplot2")
p_load("plotly")
p_load("DT")
library(pacman)
p_load("pacman")
p_load("tidyverse")
p_load("knitr")
p_load("markdown")
p_load("data.table")
p_load("sqldf")
p_load("ggplot2")
p_load("lubridate")
p_load("foreach")
p_load("RSQLite")
p_load("shiny")
p_load("shinyjs")
p_load("choroplethr")
p_load("choroplethrMaps")
p_load("DescTools")
p_load("readxl")
p_load("devtools")
p_load("ggplot2")
p_load("plotly")
p_load("DT")
runApp('9-data-products/week-4')
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
setwd("C:/dev/r-course/9-data-products/week-4")
unzip(zipfile  = "./data/lending-club-loan-data.zip")
unzip(zipfile  = "./data/lending-club-loan-data.zip", exdir=paste(getwd(), "data"))
suppressMessages(rm(list = ls()))
unzip(zipfile  = "./data/lending-club-loan-data.zip", exdir=paste(getwd(), "data"))
outdir <- paste(getwd(), "data")
outdir
unzip(zipfile  = "./data/lending-club-loan-data.zip", exdir=paste(getwd(), "/data"))
outdir <- paste(getwd(), "/data")
unzip(zipfile  = "./data/lending-club-loan-data.zip", exdir=outdir)
unzip(zipfile  = "./data/lending-club-loan-data.zip", outdir)
switch(Sys.info()[['sysname']],
Windows= {suppressMessages(setwd("C:/dev/r-course/9-data-products/week-4"))},
Linux  = {suppressMessages(setwd("~/srv/connect/apps/loan_book_analyser"))},
Darwin = {print("I'm a Mac.")})
outdir <- paste(getwd(), "/data")
unzip(zipfile  = "./data/lending-club-loan-data.zip", outdir)
shiny::runApp()
outdir <- paste(getwd(), "/data")
paste(zipfile, "lending-club-loan-data.zip")
paste(outdir, "lending-club-loan-data.zip")
paste(trimws(outdir), "lending-club-loan-data.zip")
outdir <- paste(trimws(getwd()), "/data")
paste(trimws(outdir), "lending-club-loan-data.zip")
outdir <- paste(trimws(getwd()), "data")
outdir
outdir <- paste(trimws(getwd()), "//data")
outdir
outdir <- paste0(trimws(getwd()), "data")
outdir
outdir <- paste0(trimws(getwd()), "/data")
outdir
zippedFile <- paste0(trimws(outdir), "lending-club-loan-data.zip")
zippedFile
outdir <- paste0(trimws(getwd()), "/data")
outdir
zippedFile <- paste0(trimws(outdir), "lending-club-loan-data.zip")
zippedFile
outdir <- paste0(trimws(getwd()), "/data/")
outdir
zippedFile <- paste0(trimws(outdir), "lending-club-loan-data.zip")
zippedFile
unzip(zipfile  = zippedFile, outdir)
unzip(zippedFile, outdir)
zippedFile
outdir
unzip(zippedFile, outdir)
unzip(zippedFile)
?unzip
unzip(zippedFile, exdir=outdir)
unzip(zipfile=zippedFile, exdir=outdir)
unzip(zipfile=zippedFile,exdir = outdir)
outdir <- paste0(trimws(getwd()), "/data")
outdir
zippedFile <- paste0(trimws(outdir), "/lending-club-loan-data.zip")
zippedFile
unzip(zipfile=zippedFile,exdir = outdir)
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
runApp()
source('C:/dev/r-course/9-data-products/week-4/index.R', echo=TRUE)
install.packages("rsconnect")
source('C:/dev/r-course/9-data-products/week-4/index.R', echo=TRUE)
source('C:/dev/r-course/9-data-products/week-4/index.R', echo=TRUE)
source('C:/dev/r-course/9-data-products/week-4/index.R', echo=TRUE)
shiny::runApp()
runApp()
shiny::runApp()
source('C:/dev/r-course/9-data-products/week-4/index.R', echo=TRUE)
source("C:/dev/r-course/10-capstone/quiz1.R", encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
p_load("stringr")
suppressMessages(setwd("c:/dev/r-course/10-capstone"))
blogs <- readLines("final/en_US/en_US.blogs.txt")
blogs <- readLines("final/en_US/en_US.blogs.txt")
blogs <- readLines("final/en_US/en_US.blogs.txt", local = locale(encoding = "latin1"))
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
Sys.getlocale()
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
library(tm)
?tm
???tm
??tm
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/quiz1.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
help.search()
help
help.start
help.start()
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/week2/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
repo <- new("TextRepository", .Data = list(blogs,news,twitter))
?tm
tmIndex
TermDocMatrlibrary(tm)
library(tm)
blogs <- read_file("final/en_US/en_US.blogs.txt")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
summary(data.blogs)
DescTools::Desc(data.blogs, plotit = TRUE)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
src <- DirSource("c:/dev/r-course/10-capstone/final")
corpus <- Corpus(src)
corpus[[1]]$content
strwrap(corpus[[1]])
class(corpus)
corpus
src <- DirSource("c:/dev/r-course/10-capstone/final/en_US/")
corpus <- Corpus(src)
?Corpus
corpus <- Corpus(c(data.blogs, data.news,data.twitter))
lst <- as.list(c(data.blogs, data.news, data.twitter))
corpus <- Corpus(lst)
df.blogs <- data.frame(text = unlist(sapply(data.blogs, `[`, "content")), stringsAsFactors = F)
df.twitter <- data.frame(text = unlist(sapply(data.twitter, `[`, "content")), stringsAsFactors = F)
df.news <- data.frame(text = unlist(sapply(data.news, `[`, "content")), stringsAsFactors = F)
corpus <- Corpus(c(df.blogs,df.news,df.twitter))
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
install_packages("tm", "SnowballCC", "RColorBrewer", "ggplot2", "wordcloud", "biclust","cluster", "igraph", "fpc")
source("C:/dev/r-course/10-capstone/include.r", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
lst <- list("tm", "SnowballCC", "RColorBrewer", "ggplot2", "wordcloud", "biclust", "cluster", "igraph", "fpc")
do.call("install_extra_packages", lst)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
lst <- list("tm", "SnowballCC", "RColorBrewer", "ggplot2", "wordcloud", "biclust", "cluster", "igraph", "fpc") install_extra_packages(lst)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
df.blogs <- sample(data.frame(text = unlist(sapply(data.blogs, `[`, "content")), stringsAsFactors = F), 1000)
df.blogs <- sample(data.frame(text = unlist(sapply(data.blogs, `[`, "content")), stringsAsFactors = F), 30)
sample.blogs <- sample(data.frame(text = unlist(sapply(data.blogs, `[`, "content")), stringsAsFactors = F), 100) sample.news <- sample(data.frame(text = unlist(sapply(data.news, `[`, "content")), stringsAsFactors = F), 100) sample.twitter <- sample(data.frame(text = unlist(sapply(data.twitter, `[`, "content")), stringsAsFactors = F), 100) sample.all <- c(df.blogs, df.news, df.twitter)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
corpus <- Corpus(VectorSource(list(sample.all)))
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
sample.blogs <- sample(data.frame(text = unlist(sapply(data.blogs, `[`, "content")), stringsAsFactors = F), 100) sample.news <- sample(data.frame(text = unlist(sapply(data.news, `[`, "content")), stringsAsFactors = F), 100) sample.twitter <- sample(data.frame(text = unlist(sapply(data.twitter, `[`, "content")), stringsAsFactors = F), 100) sample.all <- c(sample.blogs, sample.news, sample.twitter)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
data <- readLines(con)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
data.all <- c(data.blogs, data.news, data.twitter)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
uniGramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1)) biGramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2)) triGramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3)) uniGramMatrix <- TermDocumentMatrix(documents, control = list(tokenize = uniGramTokenizer)) biGramMatrix <- TermDocumentMatrix(documents, control = list(tokenize = biGramTokenizer)) triGramMatrix <- TermDocumentMatrix(documents, control = list(tokenize = triGramTokenizer))
uniGramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1)) biGramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2)) triGramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3)) uniGramMatrix <- TermDocumentMatrix(documents, control = list(tokenize = uniGramTokenizer)) biGramMatrix <- TermDocumentMatrix(documents, control = list(tokenize = biGramTokenizer)) triGramMatrix <- TermDocumentMatrix(documents, control = list(tokenize = triGramTokenizer))
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
sample.all <- sample(c(sample.blogs, sample.news, sample.twitter), 5000, replace = F)
sample.blogs <- sample(data.frame(text = unlist(sapply(data.blogs, `[`, "content")), stringsAsFactors = F), 20000) sample.news <- sample(data.frame(text = unlist(sapply(data.news, `[`, "content")), stringsAsFactors = F), 20000) sample.twitter <- sample(data.frame(text = unlist(sapply(data.twitter, `[`, "content")), stringsAsFactors = F), 20000) sample.all <- sample(c(sample.blogs, sample.news, sample.twitter), 5000, replace = F)
sample.blogs <- sample(data.frame(text = unlist(sapply(data.blogs, `[`, "content")), stringsAsFactors = F), 20000) sample.news <- sample(data.frame(text = unlist(sapply(data.news, `[`, "content")), stringsAsFactors = F), 20000) sample.twitter <- sample(data.frame(text = unlist(sapply(data.twitter, `[`, "content")), stringsAsFactors = F), 20000) sample.all <- sample(c(sample.blogs, sample.news, sample.twitter), 5000, replace = F) remove(sample.blogs) remove(sample.news) remove(sample.twitter)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
sample.all <- c(sample.blogs, sample.news, sample.twitter)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
corpus <- Corpus(VectorSource(list(sample.blogs, sample.news, sample.twitter)))
remove(data.blogs) remove(data.news) remove(data.twitter) remove(sample.blogs) remove(sample.news) remove(sample.twitter) remove(sample.all)
corpus <- tm_map(corpus, tolower) corpus <- tm_map(corpus, removePunctuation) corpus <- tm_map(corpus, removeNumbers) corpus <- tm_map(corpus, removeWords, stopwords("english")) corpus <- tm_map(corpus, stripWhitespace)   corpus <- tm_map(corpus, toEmpty, "#\\w+")   corpus <- tm_map(corpus, toEmpty, "(\\b\\S+\\@\\S+\\..{1,3}(\\s)?\\b)")   corpus <- tm_map(corpus, toEmpty, "@\\w+")   corpus <- tm_map(corpus, toEmpty, "http[^[:space:]]*")   corpus <- tm_map(corpus, toSpace, "/|@|\\|") writeCorpus(corpus, filenames = "corpus.txt")
# clean  ##  custom content transformers toEmpty <- content_transformer(function(x, pattern) gsub(pattern, "", x, fixed = TRUE)) toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x, fixed = TRUE)) corpus <- tm_map(corpus, tolower) corpus <- tm_map(corpus, removePunctuation) corpus <- tm_map(corpus, removeNumbers) corpus <- tm_map(corpus, removeWords, stopwords("english")) corpus <- tm_map(corpus, stripWhitespace)   corpus <- tm_map(corpus, toEmpty, "#\\w+")   corpus <- tm_map(corpus, toEmpty, "(\\b\\S+\\@\\S+\\..{1,3}(\\s)?\\b)")   corpus <- tm_map(corpus, toEmpty, "@\\w+")   corpus <- tm_map(corpus, toEmpty, "http[^[:space:]]*")   corpus <- tm_map(corpus, toSpace, "/|@|\\|")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
freqTerms <- findFreqTerms(matrix.uni)
freqTerms <- findFreqTerms(matrix.uni, lowfreq = 3000)
freqTerms <- findFreqTerms(matrix.uni, lowfreq = 5000)
freqTerms <- findFreqTerms(matrix.uni, lowfreq = 4000)
list_freqs <- lapply(corpus$dimnames$Docs,               function(i) findFreqTerms(corpus[corpus$dimnames$Docs == i], 2000))
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
df <- as.data.frame(as.matrix(corpus))
df <- as.data.frame(as.matrix(freqTerms))
df <- as.data.frame(as.matrix(dtm$dimnames$Docs))
df <- as.data.frame(as.matrix(corpus[1]))
tm <- DocumentTermMatrix(corpus)
dtm <- DocumentTermMatrix(corpus)
df <- as.data.frame(as.matrix(dtm))
df <- data.frame(t(df))
require(ggplot2) ggplot(df, aes(X127, X144)) +     geom_text(label = rownames(df),            position = position_jitter())
df <- names("word", "blog_count", "news_count", "twitter_count")
df <- colnames("word", "blog_count", "news_count", "twitter_count")
cols <- c("word", "blog_count", "news_count", "twitter_count")
colnames(df) <- cols
cols <- c("blog_count", "news_count", "twitter_count") colnames(df) <- cols
top5.blogwords <- sqldf("select * from df order by blog_count desc limit 5")
df <- as.data.frame(as.matrix(dtm))
p_load("quanteda")
summary(corpus)
dtm <- DocumentTermMatrix(corpus)
plot(dtm, terms = findFreqTerms(dtm, lowfreq = 2000)[1:25], corThreshold = 0.5)
p_load("Rgraphviz")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
setDT(df, keep.rownames = TRUE)[]
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
cols <- c("word", "blog_count", "news_count", "twitter_count")
plot(dtm, terms = findFreqTerms(dtm, lowfreq = 2000)[1:25], corThreshold = 0.5)
df <- as.data.frame(as.matrix(dtm)) # and transpose for plotting df <- data.frame(t(df)) setDT(df, keep.rownames = TRUE)[] cols <- c("word", "blog_count", "news_count", "twitter_count") colnames(df) <- cols
top5.blogwords <- sqldf("select * from df order by blog_count desc limit 5")
top5.newswords <- sqldf("select word, news_count from df order by news_count desc limit 5")
top5.twitterwords <- sqldf("select word,twitter_count from df order by twitter_count desc limit 5")
top5.blogwords <- sqldf("select word, blog_count from df order by blog_count desc limit 5") top5.newswords <- sqldf("select word, news_count from df order by news_count desc limit 5") top5.twitterwords <- sqldf("select word,twitter_count from df order by twitter_count desc limit 5")
summary(corpus)
myCorpus <- corpus(corpus)
myCorpus <- quanteda::corpus(corpus)
ggplot(top5.blogwords, aes(x = word, fill = blog_count)) +     geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +     facet_wrap(~blog_count, ncol = 1)
install.packages("Rcpp", lib="C:/Users/chris/Documents/R/win-library/3.4")
ggplot(top5.blogwords, aes(x = word, fill = blog_count)) +     geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +     facet_wrap(~blog_count, ncol = 1)
ggplot(top5.blogwords, aes(x = word, fill = blog_count)) +     geom_histogram(position = "identity", bins = 20, show.legend = FALSE,stat = "count") +     facet_wrap(~blog_count, ncol = 1)
myCorpus <- quanteda::corpus(corpus) # build a new corpus from the texts
p_load("Rcpp")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
install.packages("Rcpp")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
corpus.data <- Corpus(VectorSource(lst)) corpus.summary <- quanteda::corpus(tmVCorpus(lst))
corpus.summary <- quanteda::corpus(VCorpus(lst))
inspect(corpus.data)
nTerms(corpus.data)
nDocs(corpus.data)
meta(corpus.data)
meta(corpus.data)
meta(corpus.data[1])
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
matrix.uni <- DocumentTermMatrix(corpus.data, control = list(tokenize = tokenizer.uni))
matrix.bi <- DocumentTermMatrix(corpus.data, control = list(tokenize = tokenizer.bi))
list_freqs <- lapply(corpus.data$dimnames$Docs,               function(i) findFreqTerms(corpus.data[corpus.data$dimnames$Docs == i], 2000))
freq.terms <- findFreqTerms(matrix.uni, lowfreq = 4000) freq.expressions <- findFreqTerms(bi, lowfreq = 4000)
freq.terms <- findFreqTerms(matrix.uni, lowfreq = 4000) freq.expressions <- findFreqTerms(matrix.bi, lowfreq = 4000)
nTerms(dtm)
dtm <- DocumentTermMatrix(corpus)
#https://stackoverflow.com/questions/17294824/counting-words-in-a-single-document-from-corpus-in-r-and-putting-it-in-dataframe dtm <- DocumentTermMatrix(corpus.data)
nTerms(dtm)
matrix.tri <- DocumentTermMatrix(corpus.data, control = list(tokenize = tokenizer.tri))
tokenizer.tri <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
matrix.tri <- DocumentTermMatrix(corpus.data, control = list(tokenize = tokenizer.tri))
freq.terms <- findFreqTerms(matrix.uni, lowfreq = 4000) freq.expressions <- findFreqTerms(matrix.bi, lowfreq = 4000)
freq.terms <- findFreqTerms(matrix.uni, 160)
freq.terms <- findFreqTerms(matrix.uni, 10) freq.expressions <- findFreqTerms(matrix.bi, 10)
list_freqs()
# find freq words for each doc, one by one list_freqs <- lapply(corpus.data$dimnames$Docs,               function(i) findFreqTerms(corpus.data[corpus.data$dimnames$Docs == i], 2000))
# find freq words for each doc, one by one list_freqs <- lapply(corpus.data$dimnames$Docs,               function(i) findFreqTerms(corpus.data[corpus.data$dimnames$Docs == i], 2000))
list_freqs()
list_freqs
#Tokenize sample into Unigrams, Bigrams and Trigrams tokenizer.uni <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1)) tokenizer.bi <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2)) tokenizer.tri <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3)) matrix.uni <- DocumentTermMatrix(corpus.data, control = list(tokenize = tokenizer.uni)) matrix.bi <- DocumentTermMatrix(corpus.data, control = list(tokenize = tokenizer.bi)) freq.terms <- findFreqTerms(matrix.uni, 10) freq.expressions <- findFreqTerms(matrix.bi, 10)
plot(dtm, terms = freq.terms[1:5], corThreshold = 0.5)
freq.terms <- findFreqTerms(matrix.uni, 10)
dtm <- DocumentTermMatrix(corpus.data)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
p_load("tidytext")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
tidy_books %>%     anti_join(stop_words) %>%     count(df$word) %>%     with(wordcloud(df$word, n, max.words = 100))
p_load("tidytext")
tidy_books %>%     anti_join(stop_words) %>%     count(df$word) %>%     with(wordcloud(df$word, n, max.words = 100))
p_load("tidytext")
tidy_books %>%     anti_join(stop_words) %>%     count(df$word) %>%     with(wordcloud(df$word, n, max.words = 100))
cols <- c("word", "blog_count", "news_count", "twitter_count") colnames(df) <- cols top.blogwords <- sqldf("select word, blog_count from df order by blog_count desc limit 100") top.newswords <- sqldf("select word, news_count from df order by news_count desc limit 100") top.twitterwords <- sqldf("select word,twitter_count from df order by twitter_count desc limit 100")
top.blogwords %>%     count(df$word) %>%     with(wordcloud(df$word, n, max.words = 100))
cols <- c("word", "blog_count", "news_count", "twitter_count") colnames(df) <- cols top.blogwords <- sqldf("select word, blog_count from df order by blog_count desc limit 100") top.newswords <- sqldf("select word, news_count from df order by news_count desc limit 100") top.twitterwords <- sqldf("select word,twitter_count from df order by twitter_count desc limit 100")
df %>%     count(df$word) %>%     with(wordcloud(df$word, n, max.words = 100))
top.blogwords <- sqldf("select word, blog_count from df order by blog_count desc limit 5") top.newswords <- sqldf("select word, news_count from df order by news_count desc limit 5") top.twitterwords <- sqldf("select word,twitter_count from df order by twitter_count desc limit 5")
nTerms(dtm)
sample.data <- bind_rows(sample.blogs %>%                       mutate(person = "blogs"),                         sample.news %>%                       mutate(person = "news"),                         sample.twitter %>%                       mutate(person = "twitter"),                       ) %>%                       mutate(timestamp = ymd_hms(timestamp))
#download_zip_files() # read files and adjust for encoding data.blogs <- read_file("final/en_US/en_US.blogs.txt") data.news <- read_file("final/en_US/en_US.news.txt") data.twitter <- read_file("final/en_US/en_US.twitter.txt") #data.all <- c(data.blogs, data.news, data.twitter) #sample data to speed things up sample.blogs <- sample(data.blogs, 20000) sample.news <- sample(data.news, 20000) sample.twitter <- sample(data.twitter, 20000) sample.all <- sample(c(sample.blogs, sample.news, sample.twitter), size = 10000, replace = TRUE) sample.data <- bind_rows(sample.blogs %>%                       mutate(person = "blogs"),                         sample.news %>%                       mutate(person = "news"),                         sample.twitter %>%                       mutate(person = "twitter"),                       ) %>%                       mutate(timestamp = ymd_hms(timestamp))
sample.data <- bind_rows(sample.blogs %>%                       mutate(person = "blogs"),                         sample.news %>%                       mutate(person = "news"),                         sample.twitter %>%                       mutate(person = "twitter"),                       ) %>%                       mutate(timestamp = ymd_hms(timestamp))
sample.data <- bind_rows(sample.blogs %>%                       mutate(person = "blogs"),                         sample.news %>%                       mutate(person = "news"),                         sample.twitter %>%                       mutate(person = "twitter"),                       ))
sample.data <- bind_rows(sample.blogs %>%                       mutate(person = "blogs"),                         sample.news %>%                       mutate(person = "news"),                         sample.twitter %>%                       mutate(person = "twitter")                       )
sample.data <- bind_rows(sample.blogs %>%                       mutate(person = "blogs"),                         sample.news %>%                       mutate(person = "news"),                         sample.twitter %>%                       mutate(person = "twitter")                       )
sample.data <- bind_rows(sample.blogs %>%                       mutate(source = "blogs"),                         sample.news %>%                         mutate(source = "news"),                         sample.twitter %>%                         mutate(source = "twitter")                       )
sample.data <- bind_rows(sample.blogs %>%                       mutate(source = "blogs"),                         sample.news %>%                         mutate(source = "news"),                         sample.twitter %>%                       mutate(source = "twitter")                       )
sample.data <- bind_rows(sample.blogs %>%                       mutate(x = "blogs"),                         sample.news %>%                         mutate(x = "news"),                         sample.twitter %>%                       mutate(x = "twitter")                       )
df %>%     count(df$word) %>%     with(wordcloud(df$word, n, max.words = 100))
warnings()p_load("revealjs")
using("revealjs")
install.packages("revealjs", type = "source")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
par(mfrow=c(1,1))
wordcloud(matrix.uni, freq.uni, scale=c(9,1), max.words=40, random.order=FALSE, colors=brewer.pal(7, "Dark2"))
top.blogwords$document <- "blog"
top.newswords$document <- "news"
top.twitterwords$document <- "twitter"
wordcloud(freq.uni, matrix.uni, scale=c(9,1), max.words=40, random.order=FALSE, colors=brewer.pal(7, "Dark2"))
wordcloud(top.blogwords, 1, scale = c(9, 1), max.words = 40, random.order = FALSE, colors = brewer.pal(7, "Dark2"))
w
wordcloud(top.blogwords, top.blogwords$blog_count, scale = c(9, 1), max.words = 40, random.order = FALSE, colors = brewer.pal(7, "Dark2"))
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
dtm <- DocumentTermMatrix(corpus.data)     m <- as.matrix(dtm)     v <- sort(rowSums(m), decreasing = TRUE)     d <- data.frame(word = names(v), freq = v)     head(d, 10)
dtm <- TermDocumentMatrix(corpus.data)     m <- as.matrix(dtm)     v <- sort(rowSums(m), decreasing = TRUE)     d <- data.frame(word = names(v), freq = v)     head(d, 10)
delim <- " \\r\\n\\t.,;:\"()?!"     tokenizer.uni <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))     tokenizer.bi <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2), delimiters = delim)     tokenizer.tri <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3), delimiters = delim)     matrix.uni <- DocumentTermMatrix(corpus.data, control = list(tokenize = tokenizer.uni))     matrix.bi <- DocumentTermMatrix(corpus.data, control = list(tokenize = tokenizer.bi))     matrix.tri <- DocumentTermMatrix(corpus.data, control = list(tokenize = tokenizer.tri))     freq.uni <- findFreqTerms(matrix.uni, 5,5)     freq.bi <- findFreqTerms(matrix.bi,  5,5)     freq.tri <- findFreqTerms(matrix.bi,  5,5)
Uni_gram <- NGramTokenizer(corpus.data, Weka_control(min = 1, max = 1)) Unigram = data.frame(table(Uni_gram)) Unigram = Unigram[order(Unigram$Freq, decreasing = T),] Ug <- Unigram[1:40,]
Uni_gram <- NGramTokenizer(corpus.data, Weka_control(min = 1, max = 1))
delim <- " \\r\\n\\t.,;:\"()?!"     tokenizer.uni <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))     tokenizer.bi <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2), delimiters = delim)     tokenizer.tri <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3), delimiters = delim) dtm.uni <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.uni)) dtm.bi <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.bi)) dtm.tri <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.tri)) freq.uni <- findFreqTerms(dtm.uni, 5,5) freq.bi <- findFreqTerms(dtm.bi,  5,5) freq.tri <- findFreqTerms(dtm.bi, 5, 5)
dtm <- TermDocumentMatrix(corpus.data)     m <- as.matrix(dtm)     v <- sort(rowSums(m), decreasing = TRUE)     d <- data.frame(word = names(v), freq = v)     head(d, 10)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
delim <- " \\r\\n\\t.,;:\"()?!"     tokenizer.uni <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))     tokenizer.bi <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2), delimiters = delim)     tokenizer.tri <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3), delimiters = delim)
dtm.uni <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.uni))     dtm.bi <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.bi))     dtm.tri <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.tri))
freq.uni <- findFreqTerms(dtm.uni, 5,5)     freq.bi <- findFreqTerms(dtm.bi,  5,5)     freq.tri <- findFreqTerms(dtm.tri, 5, 5)
Uni_gram <- NGramTokenizer(corpus.data, Weka_control(min = 1, max = 1))     Unigram = data.frame(table(Uni_gram))     Unigram = Unigram[order(Unigram$Freq, decreasing = T),] Ug <- Unigram[1:40,]
Uni_gram <- NGramTokenizer(corpus.data, Weka_control(min = 1, max = 1))
delim <- " \\r\\n\\t.,;:\"()?!"     tokenizer.uni <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))     tokenizer.bi <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2), delimiters = delim)     tokenizer.tri <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3), delimiters = delim)     tdm.uni <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.uni))     tdm.bi <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.bi))     tdm.tri <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.tri))
tdm <- TermDocumentMatrix(corpus.data, control = list(tokenize = NGramTokenizer))
tdm <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.uni))
findFreqTerms(tdm, lowfreq = 2)
corpus.data <- tm_map(corpus.data, PlainTextDocument)
delim <- " \\r\\n\\t.,;:\"()?!"     tokenizer.uni <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))     tokenizer.bi <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2), delimiters = delim)     tokenizer.tri <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3), delimiters = delim)     tdm.uni <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.uni))     tdm.bi <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.bi))     tdm.tri <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.tri))     freq.uni <- findFreqTerms(dtm.uni, 5,5)     freq.bi <- findFreqTerms(dtm.bi,  5,5)     freq.tri <- findFreqTerms(dtm.tri, 5, 5)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
freq.uni <- findFreqTerms(tdm.uni, 5,5)     freq.bi <- findFreqTerms(tdm.bi,  5,5)     freq.tri <- findFreqTerms(tdm.tri, 5, 5)
Uni_gram <- NGramTokenizer(corpus.data, Weka_control(min = 1, max = 1))
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
delim <- " \\r\\n\\t.,;:\"()?!"     tokenizer.uni <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))     tokenizer.bi <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2), delimiters = delim)     tokenizer.tri <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3), delimiters = delim)     tdm.uni <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.uni))     tdm.bi <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.bi))     tdm.tri <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.tri))     freq.uni <- findFreqTerms(tdm.uni, 5,5)     freq.bi <- findFreqTerms(tdm.bi,  5,5)     freq.tri <- findFreqTerms(tdm.tri, 5, 5)
Uni_gram <- NGramTokenizer(corpus.data, Weka_control(min = 1, max = 1)) Unigram = data.frame(table(Uni_gram)) Unigram = Unigram[order(Unigram$Freq, decreasing = T),] Ug <- Unigram[1:40,]
p_load("stringi")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
Uni_gram <-  NGramTokenizer(corpus.data, Weka_control(min = 1, max = 1))
Uni_gram <-  NGramTokenizer(corpus.data, Weka_control(min = 1, max = 1))
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
p_load("tm")
## create a UnigramTokenizer (RWeka) UnigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1)) ## create a BigramTokenizer (RWeka) BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2)) ## load the english documents en_texts <- VCorpus(DirSource(directory = "data/en_US/small", encoding = "UTF-8"),                               readerControl = list(language = "en")) ## get rid of extra white spaces, stopwords, DON'T STEM YET, switch to lowercase en_texts <- tm_map(x = en_texts, FUN = removePunctuation) en_texts <- tm_map(x = en_texts, FUN = removeWords, words = stopwords(kind = "en")) en_texts <- tm_map(x = en_texts, FUN = stripWhitespace) en_texts <- tm_map(x = en_texts, FUN = tolower) ## create a TermDocumentMatrix   ## NOTE - without the "options" underneath, the TermDocumentMatrix call crashes -  ## (looks like a parallel processing issue) options(mc.cores = 1) tdmUnigram <- TermDocumentMatrix(en_texts, control = list(tokenizer = UnigramTokenizer)) tdmBigram <- TermDocumentMatrix(en_texts, control = list(tokenizer = BigramTokenizer))
## create a UnigramTokenizer (RWeka) UnigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1)) ## create a BigramTokenizer (RWeka) BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2)) ## get rid of extra white spaces, stopwords, DON'T STEM YET, switch to lowercase corpus.data <- tm_map(x = corpus.data, FUN = removePunctuation) corpus.data <- tm_map(x = corpus.data, FUN = removeWords, words = stopwords(kind = "en")) corpus.data <- tm_map(x = corpus.data, FUN = stripWhitespace) corpus.data <- tm_map(x = corpus.data, FUN = tolower) ## create a TermDocumentMatrix   ## NOTE - without the "options" underneath, the TermDocumentMatrix call crashes -  ## (looks like a parallel processing issue) options(mc.cores = 1) tdmUnigram <- TermDocumentMatrix(corpus.data, control = list(tokenizer = UnigramTokenizer)) tdmBigram <- TermDocumentMatrix(corpus.data, control = list(tokenizer = BigramTokenizer))
lst <- list(sample.blogs, sample.news, sample.twitter)     corpus.data <- Corpus(VectorSource(lst))     toEmpty <- content_transformer(function(x, pattern) gsub(pattern, "", x, fixed = TRUE))     toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x, fixed = TRUE))     corpus.data <- tm_map(corpus.data, tolower)     corpus.data <- tm_map(corpus.data, removePunctuation)     corpus.data <- tm_map(corpus.data, removeNumbers)     corpus.data <- tm_map(corpus.data, removeWords, stopwords("english"))     corpus.data <- tm_map(corpus.data, stripWhitespace)     corpus.data <- tm_map(corpus.data, PlainTextDocument)     corpus.data <- tm_map(corpus.data, toEmpty, "#\\w+")       corpus.data <- tm_map(corpus.data, toEmpty, "(\\b\\S+\\@\\S+\\..{1,3}(\\s)?\\b)")       corpus.data <- tm_map(corpus.data, toEmpty, "@\\w+")       corpus.data <- tm_map(corpus.data, toEmpty, "http[^[:space:]]*")       corpus.data <- tm_map(corpus.data, toSpace, "/|@|\\|")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
p_load("RWeka")
install.packages("RWeka")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
options(mc.cores = 1) tdmUnigram <- TermDocumentMatrix(corpus.data, control = list(tokenizer = UnigramTokenizer)) tdmBigram <- TermDocumentMatrix(corpus.data, control = list(tokenizer = BigramTokenizer))
Uni_gram <- NGramTokenizer(Cleandata, Weka_control(min = 1, max = 1)) Unigram = data.frame(table(Uni_gram)) Unigram = Unigram[order(Unigram$Freq, decreasing = T),] Ug <- Unigram[1:40,]
Uni_gram <- NGramTokenizer(Cleandata, Weka_control(min = 1, max = 1))
?RWeka
delim <- " \\r\\n\\t.,;:\"()?!"     tokenizer.uni <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))     tokenizer.bi <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2), delimiters = delim)     tokenizer.tri <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3), delimiters = delim)     tdm.uni <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.uni))     tdm.bi <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.bi))     tdm.tri <- TermDocumentMatrix(corpus.data, control = list(tokenize = tokenizer.tri))     freq.uni <- findFreqTerms(tdm.uni, 5,5)     freq.bi <- findFreqTerms(tdm.bi,  5,5)     freq.tri <- findFreqTerms(tdm.tri, 5, 5)
barplot(tdm.uni, names.arg = freq.uni, cex.names = .7, col = heat.colors(40), main = c("Frequency of one word"), las = 2)
Uni_gram <- tokenizer.uni(corpus.data)
library(rJava)
p_load("rJava")
.jinit(parameters = "-Xmx128g")
options(mc.cores = 1)
Uni_gram <- tokenizer.uni(corpus.data)
delim <- " \\r\\n\\t.,;:\"()?!"     gram1Tokenizer <- function(x) { RWeka::NGramTokenizer(x, RWeka::Weka_control(min = 1, max = 1)) }     gram2Tokenizer <- function(x) { RWeka::NGramTokenizer(x, RWeka::Weka_control(min = 2, max = 2)) }     gram3Tokenizer <- function(x) { RWeka::NGramTokenizer(x, RWeka::Weka_control(min = 3, max = 3)) }     tdm1 <- TermDocumentMatrix(corpus, control = list(tokenize = gram1Tokenizer))     tdm2 <- TermDocumentMatrix(corpus, control = list(tokenize = gram2Tokenizer))     tdm3 <- TermDocumentMatrix(corpus, control = list(tokenize = gram3Tokenizer))     gram1freq <- data.frame(word = tdm1$dimnames$Terms, freq = rowSums(sparseMatrix(i = tdm1$i, j = tdm1$j, x = tdm1$v)))     gram1freq <- arrange(gram1freq, desc(freq))     gram2freq <- data.frame(word = tdm2$dimnames$Terms, freq = rowSums(sparseMatrix(i = tdm2$i, j = tdm2$j, x = tdm2$v)))     gram2freq <- arrange(gram2freq, desc(freq))     gram3freq <- data.frame(word = tdm3$dimnames$Terms, freq = rowSums(sparseMatrix(i = tdm3$i, j = tdm3$j, x = tdm3$v)))     gram3freq <- arrange(gram3freq, desc(freq))
delim <- " \\r\\n\\t.,;:\"()?!"     gram1Tokenizer <- function(x) { RWeka::NGramTokenizer(x, RWeka::Weka_control(min = 1, max = 1)) }     gram2Tokenizer <- function(x) { RWeka::NGramTokenizer(x, RWeka::Weka_control(min = 2, max = 2)) }     gram3Tokenizer <- function(x) { RWeka::NGramTokenizer(x, RWeka::Weka_control(min = 3, max = 3)) }     tdm1 <- TermDocumentMatrix(corpus.data, control = list(tokenize = gram1Tokenizer))     tdm2 <- TermDocumentMatrix(corpus.data, control = list(tokenize = gram2Tokenizer))     stdm3 <- TermDocumentMatrix(corpus.data, control = list(tokenize = gram3Tokenizer))     gram1freq <- data.frame(word = tdm1$dimnames$Terms, freq = rowSums(sparseMatrix(i = tdm1$i, j = tdm1$j, x = tdm1$v)))     gram1freq <- arrange(gram1freq, desc(freq))     gram2freq <- data.frame(word = tdm2$dimnames$Terms, freq = rowSums(sparseMatrix(i = tdm2$i, j = tdm2$j, x = tdm2$v)))     gram2freq <- arrange(gram2freq, desc(freq))     gram3freq <- data.frame(word = tdm3$dimnames$Terms, freq = rowSums(sparseMatrix(i = tdm3$i, j = tdm3$j, x = tdm3$v)))     gram3freq <- arrange(gram3freq, desc(freq))
p_load("Matrix")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
install.packages("rJava", dependencies = TRUE)
install.packages("RWeka", dependencies = TRUE)
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
data.frame(gram1 = gram1freq$word[1:10], gram2 = gram2freq$word[1:10], gram3 = gram3freq$word[1:10])
data.graph <-    data.frame(gram1 = gram1freq$word[1:10], gram2 = gram2freq$word[1:10], gram3 = gram3freq$word[1:10])
par(mfrow=c(1,1))     wordcloud(data.graph$gram1, scale = c(9, 1), max.words = 40, random.order = FALSE, colors = brewer.pal(7, "Dark2"))
wordcloud(data.graph$gram2, scale = c(9, 1), max.words = 40, random.order = FALSE, colors = brewer.pal(7, "Dark2"))
wordcloud(data.graph$gram3, scale = c(9, 1), max.words = 40, random.order = FALSE, colors = brewer.pal(7, "Dark2"))
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
g1 <- ggplot(data.graph[0], aes(x = reorder(data.graph[0]$word, data.graph[0]$freq), y = data.graph[0]$freq)) +     geom_bar(stat = "identity", fill = "red") +     ggtitle("1-gram") +     xlab("1-grams") + ylab("Frequency")
g1
g1 <- ggplot(data.graph[0], aes(x = word, y = freq)) +     geom_bar(stat = "identity", fill = "red") +     ggtitle("1-gram") +     xlab("1-grams") + ylab("Frequency") g1
data.graph[0] <- data.frame(word = unlist(word))
data.graph[0]
data.graph$gram1
gram1freq <= sqldf("select * from gram1freq where freq > 4000")
gram1freq <- sqldf("select * from gram1freq where freq > 4000")
g1 <- ggplot(gram1freq, aes(x = word, y = freq)) +     geom_bar(stat = "identity", fill = "red") +     ggtitle("1-gram") +     xlab("1-grams") + ylab("Frequency")
g1
gram2freq <- sqldf("select * from gram2freq where freq > 4000 order by freq desc")
g2 <- ggplot(gram2freq, aes(x = word, y = freq)) +     geom_bar(stat = "identity", fill = "green") +     ggtitle("2-gram") +     xlab("2-grams") + ylab("Frequency") g1
g2 <- ggplot(gram2freq, aes(x = word, y = freq)) +     geom_bar(stat = "identity", fill = "green") +     ggtitle("2-gram") +     xlab("2-grams") + ylab("Frequency") g2
g1 <- ggplot(gram1freq, aes(x = word, y = freq)) +     geom_bar(stat = "identity", fill = "red") +     ggtitle("1-gram") +     xlab("1-grams") + ylab("Frequency") g1
gram3freq <- sqldf("select * from gram3freq where freq > 4000 order by freq desc")
g3 <- ggplot(gram3freq, aes(x = word, y = freq)) +     geom_bar(stat = "identity", fill = "blue") +     ggtitle("3-gram") +     xlab("3-grams") + ylab("Frequency") g3
gram3freq <- data.frame(word = tdm3$dimnames$Terms, freq = rowSums(sparseMatrix(i = tdm3$i, j = tdm3$j, x = tdm3$v)))     gram3freq <- sqldf("select * from gram3freq where freq > 4000 order by freq desc")
g3 <- ggplot(gram3freq, aes(x = word, y = freq)) +     geom_bar(stat = "identity", fill = "blue") +     ggtitle("3-gram") +     xlab("3-grams") + ylab("Frequency") g3
wordcloud(names(gram1freq), gram1freq, min.freq = 25, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"))
wordcloud(gram1freq@names, gram1freq, min.freq = 25, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"))
wordcloud(gram1freq@word, gram1freq@freq, min.freq = 25, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"))
wordcloud(gram1freq@word, gram1freq@freq,  max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"))
wordcloud(gram1freq@word, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"))
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
source("C:/dev/r-course/10-capstone/milestone-report.R", echo = TRUE, encoding = "Windows-1252")
wordcloud(gram1freq@word, gram1freq@freq,  max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"))
wordcloud(gram1freq$word, gram1freq$freq,  max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2"))
wordcloud(gram2freq$word, gram2freq$freq, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "yellow"))
wordcloud(gram1freq$word, gram1freq$freq,  max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "red"))
wordcloud(gram1freq$word, gram1freq$freq,  max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Accent"))
wordcloud(gram1freq$word, gram1freq$freq,  max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Set1"))
wordcloud(gram2freq$word, gram2freq$freq, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Set2"))
wordcloud(gram3freq$word, gram3freq$freq, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Seet3"))
wordcloud(gram3freq$word, gram3freq$freq, max.words = 200, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "Set3"))
